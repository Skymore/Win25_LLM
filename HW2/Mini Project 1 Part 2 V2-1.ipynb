{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment aims to introduce students to working with the BEIR dataset for information retrieval tasks. Students will:\n",
    "\n",
    "- Understand the structure of the BEIR dataset and preprocess the data.\n",
    "- Implement a system to encode queries and documents using embeddings.\n",
    "- Calculate similarity scores to rank documents based on relevance.\n",
    "- Evaluate the system's performance using metrics like Mean Average Precision (MAP).\n",
    "- Modify and fine-tune models for better retrieval results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First start by looking into the Dataset and understanding its structure.\n",
    "This will help you understand how the dataset is formed, which will be useful in the later stages of the Assignment\n",
    "\n",
    "https://huggingface.co/datasets/BeIR/nfcorpus\n",
    "\n",
    "https://huggingface.co/datasets/BeIR/nfcorpus-qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assignment consists of two key tasks: Ranking Documents and Fine-Tuning the Sentence Transformer Model. \n",
    "# Students will be graded based on their implementation and their written report.\n",
    "\n",
    "# Mention the team/Individual contributions as a part of the report..!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking Documents Report (10 Points)\n",
    "\n",
    "# Students must analyze which encoding methods performed best for document ranking.\n",
    "\n",
    "# What to include in your report:\n",
    "    \n",
    "# Comparison of Encoding Methods \n",
    "\n",
    "    # Compare GloVe embeddings vs. Sentence Transformer embeddings.\n",
    "    # Which method ranked documents better?\n",
    "    # Did the top-ranked documents make sense?\n",
    "    # How does cosine similarity behave with different embeddings?\n",
    "\n",
    "# Observations on Cosine Similarity & Ranking \n",
    "\n",
    "    # Did the ranking appear meaningful?\n",
    "    # Were there cases where documents that should be highly ranked were not?\n",
    "    # What are possible explanations for incorrect rankings?\n",
    "\n",
    "# Possible Improvements\n",
    "\n",
    "    # What can be done to improve document ranking?\n",
    "    # Would a different distance metric (e.g., Euclidean, Manhattan) help?\n",
    "    # Would preprocessing the queries or documents (e.g., removing stopwords) improve ranking?\n",
    "\n",
    "\n",
    "# Fine-Tuning Report (15 Points)\n",
    "\n",
    "# After fine-tuning, students must compare different training approaches and reflect on their findings.\n",
    "\n",
    "# What to include in your report:\n",
    "    \n",
    "# Comparison of Different Training Strategies \n",
    "\n",
    "    # [anchor, positive] vs [anchor, positive, negative].\n",
    "    # Which approach seemed to improve ranking?\n",
    "    # How did the model behave differently?\n",
    "\n",
    "# Impact on MAP Score \n",
    "\n",
    "    # Did fine-tuning improve or hurt the Mean Average Precision (MAP) score?\n",
    "    # If MAP decreased, why might that be?\n",
    "    # Is fine-tuning always necessary for retrieval models?\n",
    "\n",
    "# Observations on Training Loss & Learning Rate \n",
    "\n",
    "    # Did the loss converge?\n",
    "    # Was the learning rate too high or too low?\n",
    "    # How did freezing/unfreezing layers impact training?\n",
    "\n",
    "# Future Improvements \n",
    "\n",
    "    # Would training with more negatives help?\n",
    "    # Would changing the loss function (e.g., using Softmax Loss) improve performance?\n",
    "    # Could increasing the number of epochs lead to a better model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: sentence_transformers in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: filelock in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from sentence_transformers) (4.48.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from sentence_transformers) (1.15.1)\n",
      "Requirement already satisfied: Pillow in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: sympy in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sky/miniforge3/envs/llm596/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4b76f059f94dcc83491e0ec3731373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create your API token from your Hugging Face Account. Make sure to save it in text file or notepad for future use.\n",
    "# Will need to add it once per section\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "\n",
    "class TextSimilarityModel:\n",
    "    def __init__(self, corpus_name, rel_name, model_name='all-MiniLM-L6-v2', top_k=10):\n",
    "        \"\"\"\n",
    "        Initialize the model with datasets and pre-trained sentence transformer.\n",
    "        \"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.corpus_name = corpus_name\n",
    "        self.rel_name = rel_name\n",
    "        self.top_k = top_k\n",
    "        self.load_data()\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load and filter datasets based on test queries and documents.\n",
    "        \"\"\"\n",
    "        # Load query and document datasets\n",
    "        dataset_queries = load_dataset(self.corpus_name, \"queries\")\n",
    "        dataset_docs = load_dataset(self.corpus_name, \"corpus\")\n",
    "\n",
    "        # Extract queries and documents\n",
    "        self.queries = dataset_queries[\"queries\"][\"text\"]\n",
    "        self.query_ids = dataset_queries[\"queries\"][\"_id\"]\n",
    "        self.documents = dataset_docs[\"corpus\"][\"text\"]\n",
    "        self.document_ids = dataset_docs[\"corpus\"][\"_id\"]\n",
    "\n",
    "        # Filter queries and documents and build relevant queries and documents mapping based on test set\n",
    "        test_qrels = load_dataset(self.rel_name)[\"test\"]\n",
    "        self.filtered_test_query_ids = set(test_qrels[\"query-id\"])\n",
    "        self.filtered_test_doc_ids = set(test_qrels[\"corpus-id\"])\n",
    "\n",
    "        self.test_queries = [q for qid, q in zip(self.query_ids, self.queries) if qid in self.filtered_test_query_ids]\n",
    "        self.test_query_ids = [qid for qid in self.query_ids if qid in self.filtered_test_query_ids]\n",
    "        self.test_documents = [doc for did, doc in zip(self.document_ids, self.documents) if did in self.filtered_test_doc_ids]\n",
    "        self.test_document_ids = [did for did in self.document_ids if did in self.filtered_test_doc_ids]\n",
    "\n",
    "        self.test_query_id_to_relevant_doc_ids = {qid: [] for qid in self.test_query_ids}\n",
    "        for qid, doc_id in zip(test_qrels[\"query-id\"], test_qrels[\"corpus-id\"]):\n",
    "            if qid in self.test_query_id_to_relevant_doc_ids:\n",
    "                self.test_query_id_to_relevant_doc_ids[qid].append(doc_id)\n",
    "                \n",
    "        ## Code Below this is used for creating the training set \n",
    "        # Build query and document id to text mapping\n",
    "        self.query_id_to_text = {query_id:query for query_id, query in zip(self.query_ids, self.queries)}\n",
    "        self.document_id_to_text = {document_id:document for document_id, document in zip(self.document_ids, self.documents)}\n",
    "\n",
    "        # Build relevant queries and documents mapping based on train set\n",
    "        train_qrels = load_dataset(self.rel_name)[\"train\"]\n",
    "        self.train_query_id_to_relevant_doc_ids = {qid: [] for qid in train_qrels[\"query-id\"]}\n",
    "\n",
    "        for qid, doc_id in zip(train_qrels[\"query-id\"], train_qrels[\"corpus-id\"]):\n",
    "            if qid in self.train_query_id_to_relevant_doc_ids:\n",
    "                # Append the document ID to the relevant doc mapping\n",
    "                self.train_query_id_to_relevant_doc_ids[qid].append(doc_id)\n",
    "        \n",
    "        # Filter queries and documents and build relevant queries and documents mapping based on validation set  \n",
    "        #TODO Put your code here. \n",
    "        ###########################################################################\n",
    "        try:\n",
    "            val_qrels = load_dataset(self.rel_name)['validation']\n",
    "            self.filtered_val_query_ids = set(val_qrels['query-id'])\n",
    "            self.filtered_val_doc_ids = set(val_qrels['corpus-id'])\n",
    "\n",
    "            val_query_pairs = [\n",
    "                (qid, query) for qid, query in zip(self.query_ids, self.queries) \n",
    "                if qid in self.filtered_val_query_ids\n",
    "            ]\n",
    "            self.val_query_ids = [pair[0] for pair in val_query_pairs]\n",
    "            self.val_queries = [pair[1] for pair in val_query_pairs]\n",
    "\n",
    "            val_doc_pairs = [\n",
    "                (did, doc) for did, doc in zip(self.document_ids, self.documents) \n",
    "                if did in self.filtered_val_doc_ids\n",
    "            ]\n",
    "            self.val_document_ids = [pair[0] for pair in val_doc_pairs]\n",
    "            self.val_documents = [pair[1] for pair in val_doc_pairs]\n",
    "\n",
    "            self.val_query_id_to_relevant_doc_ids = {qid: [] for qid in self.val_query_ids}\n",
    "            for qid, doc_id in zip(val_qrels['query-id'], val_qrels['corpus-id']):\n",
    "                if qid in self.val_query_id_to_relevant_doc_ids:\n",
    "                    self.val_query_id_to_relevant_doc_ids[qid].append(doc_id)\n",
    "        except Exception as e:\n",
    "            print('No validation split available. Skipping validation set creation.')\n",
    "        ###########################################################################\n",
    "        \n",
    "\n",
    "    #Task 1: Encode Queries and Documents (10 Pts)\n",
    "\n",
    "    def encode_with_glove(self, glove_file_path: str, sentences: list[str]) -> list[np.ndarray]:\n",
    "\n",
    "        \"\"\"\n",
    "        # Inputs:\n",
    "            - glove_file_path (str): Path to the GloVe embeddings file (e.g., \"glove.6B.50d.txt\").\n",
    "            - sentences (list[str]): A list of sentences to encode.\n",
    "\n",
    "        # Output:\n",
    "            - list[np.ndarray]: A list of sentence embeddings \n",
    "            \n",
    "        (1) Encodes sentences by averaging GloVe 50d vectors of words in each sentence.\n",
    "        (2) Return a sequence of embeddings of the sentences.\n",
    "        Download the glove vectors from here. \n",
    "        https://nlp.stanford.edu/data/glove.6B.zip\n",
    "        Handle unknown words by using zero vectors\n",
    "        \"\"\"\n",
    "        #TODO Put your code here. \n",
    "        ###########################################################################\n",
    "        # Load GloVe embeddings dictionary\n",
    "        glove_dict = {}\n",
    "        with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                # Skip incomplete lines (should contain one word + 50 dimensions)\n",
    "                if len(parts) < 51:\n",
    "                    continue\n",
    "                word = parts[0]\n",
    "                vector = np.array(parts[1:], dtype=float)\n",
    "                glove_dict[word] = vector\n",
    "\n",
    "        embedding_dim = len(next(iter(glove_dict.values())))\n",
    "        embeddings = []\n",
    "\n",
    "        # Encode each sentence by averaging word vectors\n",
    "        for sentence in sentences:\n",
    "            tokens = sentence.split()\n",
    "            vecs = []\n",
    "            for token in tokens:\n",
    "                # Use lower-case tokens to match the GloVe keys\n",
    "                token_vec = glove_dict.get(token.lower())\n",
    "                if token_vec is None:\n",
    "                    token_vec = np.zeros(embedding_dim)\n",
    "                vecs.append(token_vec)\n",
    "            if vecs:\n",
    "                sentence_embedding = np.mean(vecs, axis=0)\n",
    "            else:\n",
    "                sentence_embedding = np.zeros(embedding_dim)\n",
    "            embeddings.append(sentence_embedding)\n",
    "\n",
    "        return embeddings\n",
    "        ###########################################################################\n",
    "\n",
    "    #Task 2: Calculate Cosine Similarity and Rank Documents (20 Pts)\n",
    "    \n",
    "    def rank_documents(self, encoding_method: str = 'sentence_transformer') -> None:\n",
    "        \"\"\"\n",
    "         # Inputs:\n",
    "            - encoding_method (str): The method used for encoding queries/documents. \n",
    "                             Options: ['glove', 'sentence_transformer'].\n",
    "\n",
    "        # Output:\n",
    "            - None (updates self.query_id_to_ranked_doc_ids with ranked document IDs).\n",
    "    \n",
    "        (1) Compute cosine similarity between each document and the query\n",
    "        (2) Rank documents for each query and save the results in a dictionary \"query_id_to_ranked_doc_ids\" \n",
    "            This will be used in \"mean_average_precision\"\n",
    "            Example format {2: [125, 673], 35: [900, 822]}\n",
    "        \"\"\"\n",
    "        if encoding_method == 'glove':\n",
    "            query_embeddings = self.encode_with_glove(\"glove.6B.50d.txt\", self.queries)\n",
    "            document_embeddings = self.encode_with_glove(\"glove.6B.50d.txt\", self.documents)\n",
    "        elif encoding_method == 'sentence_transformer':\n",
    "            query_embeddings = self.model.encode(self.queries)\n",
    "            document_embeddings = self.model.encode(self.documents)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid encoding method. Choose 'glove' or 'sentence_transformer'.\")\n",
    "        \n",
    "        #TODO Put your code here.\n",
    "        ###########################################################################\n",
    "        # Map test query IDs to their indices in the full query list.\n",
    "        test_query_indices = [self.query_ids.index(qid) for qid in self.test_query_ids]\n",
    "        # Map test document IDs to their indices in the full document list.\n",
    "        test_doc_indices = [self.document_ids.index(doc_id) for doc_id in self.test_document_ids]\n",
    "        \n",
    "        # Subset the embeddings for test queries and documents using the computed indices.\n",
    "        test_query_embeddings = [query_embeddings[i] for i in test_query_indices]\n",
    "        test_document_embeddings = [document_embeddings[i] for i in test_doc_indices]\n",
    "        \n",
    "        # Now compute the cosine similarity matrix only on test queries vs test documents.\n",
    "        sim_matrix = cosine_similarity(test_query_embeddings, test_document_embeddings)\n",
    "\n",
    "        # Initialize the dictionary for storing ranked document IDs.\n",
    "        self.query_id_to_ranked_doc_ids = {}\n",
    "        \n",
    "        # For each test query, rank the documents based on their similarity scores.\n",
    "        for i, qid in enumerate(self.test_query_ids):\n",
    "            sim_scores = sim_matrix[i]\n",
    "            # Sort document indices by descending similarity.\n",
    "            ranked_indices = np.argsort(sim_scores)[::-1]\n",
    "            ranked_doc_ids = [self.test_document_ids[idx] for idx in ranked_indices]\n",
    "            self.query_id_to_ranked_doc_ids[qid] = ranked_doc_ids\n",
    "        ###########################################################################\n",
    "\n",
    "    @staticmethod\n",
    "    def average_precision(relevant_docs: list[str], candidate_docs: list[str]) -> float:\n",
    "        \"\"\"\n",
    "        # Inputs:\n",
    "            - relevant_docs (list[str]): A list of document IDs that are relevant to the query.\n",
    "            - candidate_docs (list[str]): A list of document IDs ranked by the model.\n",
    "\n",
    "        # Output:\n",
    "            - float: The average precision score\n",
    "    \n",
    "        Compute average precision for a single query.\n",
    "        \"\"\"\n",
    "        y_true = [1 if doc_id in relevant_docs else 0 for doc_id in candidate_docs]\n",
    "        precisions = [np.mean(y_true[:k+1]) for k in range(len(y_true)) if y_true[k]]\n",
    "        return np.mean(precisions) if precisions else 0\n",
    "\n",
    "    #Task 3: Calculate Evaluate System Performance (10 Pts)\n",
    "    \n",
    "    def mean_average_precision(self) -> float:\n",
    "        \"\"\"\n",
    "        # Inputs:\n",
    "            - None (uses ranked documents stored in self.query_id_to_ranked_doc_ids).\n",
    "\n",
    "        # Output:\n",
    "            - float: The MAP score, computed as the mean of all average precision scores.\n",
    "    \n",
    "        (1) Compute mean average precision for all queries using the \"average_precision\" function.\n",
    "        (2) Compute the mean of all average precision scores\n",
    "        Return the mean average precision score\n",
    "        \n",
    "        reference: https://www.evidentlyai.com/ranking-metrics/mean-average-precision-map\n",
    "        https://towardsdatascience.com/map-mean-average-precision-might-confuse-you-5956f1bfa9e2\n",
    "        \"\"\"\n",
    "         #TODO Put your code here. \n",
    "        ###########################################################################\n",
    "        ap_scores = []\n",
    "        for qid in self.test_query_ids:\n",
    "            relevant_docs = self.test_query_id_to_relevant_doc_ids.get(qid, [])\n",
    "            candidate_docs = self.query_id_to_ranked_doc_ids.get(qid, [])\n",
    "            ap = self.average_precision(relevant_docs, candidate_docs)\n",
    "            ap_scores.append(ap)\n",
    "        return np.mean(ap_scores) if ap_scores else 0.0\n",
    "        ###########################################################################\n",
    "    \n",
    "    #Task 4: Ranking the Top 10 Documents based on Similarity Scores (10 Pts)\n",
    "   \n",
    "    def show_ranking_documents(self, example_query: str) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        # Inputs:\n",
    "            - example_query (str): A query string for which top-ranked documents should be displayed.\n",
    "\n",
    "        # Output:\n",
    "            - None (prints the ranked documents along with similarity scores).\n",
    "        \n",
    "        (1) rank documents with given query with cosine similarity scores\n",
    "        (2) prints the top 10 results along with its similarity score.\n",
    "        \n",
    "        \"\"\"\n",
    "        #TODO Put your code here. \n",
    "        query_embedding = self.model.encode(example_query)\n",
    "        document_embeddings = self.model.encode(self.documents)\n",
    "        ###########################################################################\n",
    "        # Compute cosine similarity scores between the query and all documents\n",
    "        sim_scores = cosine_similarity([query_embedding], document_embeddings)[0]\n",
    "\n",
    "        # Get indices of top K documents based on the similarity scores\n",
    "        top_k_indices = np.argsort(sim_scores)[::-1][:self.top_k]\n",
    "\n",
    "        print(f'Top {self.top_k} documents for the query: \"{example_query}\"')\n",
    "        for rank, idx in enumerate(top_k_indices, start=1):\n",
    "            doc_id = self.document_ids[idx]\n",
    "            score = sim_scores[idx]\n",
    "            print(f'Rank {rank}: Document ID: {doc_id}, Similarity Score: {score:.4f}')\n",
    "            ###########################################################################\n",
    "      \n",
    "    #Task 5:Fine tune the sentence transformer model (25 Pts)\n",
    "    # Students are not graded on achieving a high MAP score. \n",
    "    # The key is to show understanding, experimentation, and thoughtful analysis.\n",
    "    \n",
    "    def fine_tune_model(self, batch_size: int = 32, num_epochs: int = 3, save_model_path: str = \"finetuned_senBERT\") -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Fine-tunes the model using MultipleNegativesRankingLoss.\n",
    "        (1) Prepare training examples from `self.prepare_training_examples()`\n",
    "        (2) Experiment with [anchor, positive] vs [anchor, positive, negative]\n",
    "        (3) Define a loss function (`MultipleNegativesRankingLoss`)\n",
    "        (4) Freeze all model layers except the final layers\n",
    "        (5) Train the model with the specified learning rate\n",
    "        (6) Save the fine-tuned model\n",
    "        \"\"\"\n",
    "        #TODO Put your code here.\n",
    "        ###########################################################################\n",
    "        \"\"\"\n",
    "        Fine-tunes the model using MultipleNegativesRankingLoss.\n",
    "        \"\"\"\n",
    "        # Import torch at the beginning of the method\n",
    "        import torch\n",
    "        from torch.utils.data import DataLoader\n",
    "        import time\n",
    "        from datetime import timedelta\n",
    "        \n",
    "        # Check device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # Move model to GPU if available\n",
    "        self.model = self.model.to(device)\n",
    "        \n",
    "        # Prepare training examples\n",
    "        train_examples = self.prepare_training_examples()\n",
    "        print(f\"Number of training examples: {len(train_examples)}\")\n",
    "        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "        \n",
    "        # Define the loss function\n",
    "        train_loss = losses.MultipleNegativesRankingLoss(self.model)\n",
    "        \n",
    "        # Print model parameters status\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Freeze all layers except the final layer\n",
    "        for name, param in self.model.named_parameters():\n",
    "            # Only unfreeze the final transformer layer (layer.5 for all-MiniLM-L6-v2)\n",
    "            if 'layer.5' in name:  # all-MiniLM-L6-v2 has 6 layers (0-5)\n",
    "                param.requires_grad = True\n",
    "                print(f\"Unfreezing: {name}\")\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Print trainable parameters to verify\n",
    "        print(\"\\nTrainable parameters:\")\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f\"- {name}\")\n",
    "                \n",
    "        # Training loop with timing\n",
    "        start_time = time.time()\n",
    "        print(\"\\nStarting training...\")\n",
    "        \n",
    "        # Fine-tune the model with warmup\n",
    "        warmup_steps = int(len(train_dataloader) * 0.1)  # 10% of training data for warmup\n",
    "        self.model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=num_epochs,\n",
    "            warmup_steps=warmup_steps,\n",
    "            show_progress_bar=True,\n",
    "            output_path=save_model_path,\n",
    "            checkpoint_path=f\"{save_model_path}_checkpoint\",\n",
    "            checkpoint_save_steps=len(train_dataloader),\n",
    "            callback=lambda score, epoch, steps: print(f\"\\nEpoch {epoch}: Score {score:.4f}\")\n",
    "        )\n",
    "        \n",
    "        # Calculate and print training time\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"\\nTraining completed in {str(timedelta(seconds=int(training_time)))}\")\n",
    "        \n",
    "        # Save the model\n",
    "        print(f\"Saving model to {save_model_path}\")\n",
    "        self.model.save(save_model_path)\n",
    "        print(\"Model saved successfully!\")\n",
    "        ###########################################################################\n",
    "\n",
    "    # Take a careful look into how the training set is created\n",
    "    def prepare_training_examples(self) -> list[InputExample]:\n",
    "\n",
    "        \"\"\"\n",
    "        Prepares training examples from the training data.\n",
    "        # Inputs:\n",
    "            - None (uses self.train_query_id_to_relevant_doc_ids to create training pairs).\n",
    "\n",
    "         # Output:\n",
    "            Output: - list[InputExample]: A list of training samples containing [anchor, positive] or [anchor, positive, negative].\n",
    "            \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        Prepares training examples from the training data.\n",
    "        \"\"\"\n",
    "        train_examples = []\n",
    "        import random\n",
    "        from datetime import timedelta\n",
    "        from tqdm import tqdm\n",
    "        \n",
    "        print(\"\\nPreparing training examples...\")\n",
    "        total_queries = len(self.train_query_id_to_relevant_doc_ids)\n",
    "        print(f\"Total queries to process: {total_queries}\")\n",
    "        \n",
    "        # Count total examples that will be created\n",
    "        total_examples = sum(len(doc_ids) for doc_ids in self.train_query_id_to_relevant_doc_ids.values())\n",
    "        print(f\"Expected total training examples: {total_examples}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Create progress bar\n",
    "        pbar = tqdm(self.train_query_id_to_relevant_doc_ids.items(), \n",
    "                    total=total_queries,\n",
    "                    desc=\"Processing queries\")\n",
    "        \n",
    "        for qid, doc_ids in pbar:\n",
    "            anchor = self.query_id_to_text[qid]\n",
    "            # Precompute negative candidates for current query using set subtraction for efficiency\n",
    "            relevant_set = set(self.train_query_id_to_relevant_doc_ids.get(qid, []))\n",
    "            negative_candidates = list(set(self.document_ids) - relevant_set)\n",
    "            \n",
    "            for doc_id in doc_ids:\n",
    "                positive = self.document_id_to_text[doc_id]\n",
    "                \n",
    "                # Update progress bar description with current query details\n",
    "                pbar.set_description(f\"Query {qid}: {len(doc_ids)} docs\")\n",
    "                \n",
    "                # Build texts list without an explicit else branch.\n",
    "                texts = [anchor, positive]\n",
    "                if negative_candidates:\n",
    "                    texts.append(self.document_id_to_text[random.choice(negative_candidates)])\n",
    "                train_examples.append(InputExample(texts=texts))\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\nTraining examples preparation completed in {timedelta(seconds=int(elapsed_time))}\")\n",
    "        print(f\"Final number of training examples: {len(train_examples)}\")\n",
    "        \n",
    "        return train_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking with sentence_transformer...\n",
      "Mean Average Precision: 0.1717425840743641\n",
      "Ranking with glove...\n",
      "Mean Average Precision: 0.028223179599728726\n",
      "Top 10 documents for the query: \"Breast Cancer Cells Feed on Cholesterol\"\n",
      "Rank 1: Document ID: MED-2439, Similarity Score: 0.6946\n",
      "Rank 2: Document ID: MED-2434, Similarity Score: 0.6723\n",
      "Rank 3: Document ID: MED-2440, Similarity Score: 0.6473\n",
      "Rank 4: Document ID: MED-2427, Similarity Score: 0.5877\n",
      "Rank 5: Document ID: MED-2774, Similarity Score: 0.5498\n",
      "Rank 6: Document ID: MED-838, Similarity Score: 0.5406\n",
      "Rank 7: Document ID: MED-2430, Similarity Score: 0.5205\n",
      "Rank 8: Document ID: MED-2102, Similarity Score: 0.5141\n",
      "Rank 9: Document ID: MED-2437, Similarity Score: 0.5081\n",
      "Rank 10: Document ID: MED-5066, Similarity Score: 0.5012\n"
     ]
    }
   ],
   "source": [
    "# Initialize and use the model\n",
    "model = TextSimilarityModel(\"BeIR/nfcorpus\", \"BeIR/nfcorpus-qrels\")\n",
    "\n",
    "# Compare the outputs \n",
    "print(\"Ranking with sentence_transformer...\")\n",
    "model.rank_documents(encoding_method='sentence_transformer')\n",
    "map_score = model.mean_average_precision()\n",
    "print(\"Mean Average Precision:\", map_score)\n",
    "\n",
    "# Compare the outputs \n",
    "print(\"Ranking with glove...\")\n",
    "model.rank_documents(encoding_method='glove')\n",
    "map_score = model.mean_average_precision()\n",
    "print(\"Mean Average Precision:\", map_score)\n",
    "\n",
    "\n",
    "model.show_ranking_documents(\"Breast Cancer Cells Feed on Cholesterol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Preparing training examples...\n",
      "Total queries to process: 2590\n",
      "Expected total training examples: 110575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query PLAIN-3474: 83 docs: 100%|██████████| 2590/2590 [00:51<00:00, 50.66it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training examples preparation completed in 0:00:51\n",
      "Final number of training examples: 110575\n",
      "Number of training examples: 110575\n",
      "Total parameters: 22,713,216\n",
      "Trainable parameters: 22,713,216\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.self.query.weight\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.self.query.bias\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.self.key.weight\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.self.key.bias\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.self.value.weight\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.self.value.bias\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.output.dense.weight\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.output.dense.bias\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.intermediate.dense.weight\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.intermediate.dense.bias\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.output.dense.weight\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.output.dense.bias\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.output.LayerNorm.weight\n",
      "Unfreezing: 0.auto_model.encoder.layer.5.output.LayerNorm.bias\n",
      "\n",
      "Trainable parameters:\n",
      "- 0.auto_model.encoder.layer.5.attention.self.query.weight\n",
      "- 0.auto_model.encoder.layer.5.attention.self.query.bias\n",
      "- 0.auto_model.encoder.layer.5.attention.self.key.weight\n",
      "- 0.auto_model.encoder.layer.5.attention.self.key.bias\n",
      "- 0.auto_model.encoder.layer.5.attention.self.value.weight\n",
      "- 0.auto_model.encoder.layer.5.attention.self.value.bias\n",
      "- 0.auto_model.encoder.layer.5.attention.output.dense.weight\n",
      "- 0.auto_model.encoder.layer.5.attention.output.dense.bias\n",
      "- 0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "- 0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "- 0.auto_model.encoder.layer.5.intermediate.dense.weight\n",
      "- 0.auto_model.encoder.layer.5.intermediate.dense.bias\n",
      "- 0.auto_model.encoder.layer.5.output.dense.weight\n",
      "- 0.auto_model.encoder.layer.5.output.dense.bias\n",
      "- 0.auto_model.encoder.layer.5.output.LayerNorm.weight\n",
      "- 0.auto_model.encoder.layer.5.output.LayerNorm.bias\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6a2bf23c324a528268208b77f41138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34560' max='34560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34560/34560 34:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.722200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.548800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.486100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.466100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.437400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.422700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.339700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.343200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>3.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.266300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.284400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.270600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>3.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>3.199700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>3.169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>3.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>3.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>3.173600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>3.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>3.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>3.155500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>3.134900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>3.132400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>3.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>3.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>3.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>3.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>3.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>3.121100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>3.127900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>3.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>3.090500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>3.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>3.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>3.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>3.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>3.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>3.081900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>3.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>3.081500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>3.081900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>3.066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>3.067800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>3.076300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>3.091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>3.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>3.074900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>3.057700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in 0:34:20\n",
      "Saving model to finetuned_senBERT_train_v2\n",
      "Model saved successfully!\n",
      "Mean Average Precision: 0.2133299787073085\n"
     ]
    }
   ],
   "source": [
    "# Finetune all-MiniLM-L6-v2 sentence transformer model\n",
    "model.fine_tune_model(batch_size=32, num_epochs=10, save_model_path=\"finetuned_senBERT_train_v2\")  # Adjust batch size and epochs as needed\n",
    "\n",
    "model.rank_documents()\n",
    "map_score = model.mean_average_precision()\n",
    "print(\"Mean Average Precision:\", map_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm596",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
